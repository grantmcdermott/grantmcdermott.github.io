{
  "hash": "574b272fefb309db435ce74e20a9e7de",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Reshape benchmarks\"\ndescription: \"Going wide to long with sparse data\"\ndate: \"2020-06-30\"\ncategories: [R, Stata, data science]\ntoc: true\n---\n\n\n\n## Motivation\n\nOver on Twitter, I was reply-tagged in a [tweet thread](https://twitter.com/RyanReedHill/status/1277004562285555712) by Ryan Hill. Ryan shows how he overcomes a problem that arises when reshaping a sparse (i.e. unbalanced) dataset in Stata. Namely, how can you cut down on the computation time that Stata wastes with all the missing values, especially when reshaping really wide data? Ryan's clever solution is very much in the [split-apply-combine](https://www.jstatsoft.org/article/view/v040i01) mould. Manually split the data into like groups (i.e. sharing the same columns), drop any missing observations, and then reshape on those before recombining everything at the end. It turns out that this is a *lot* faster than Stata's default reshape command... and there is even a package (**sreshape**) that implements this for you.\n\nSo far so good. But [I was asked](https://twitter.com/p_purushottam/status/1277141715938205700) what the R equivalent of this approach would be. It's pretty easy to implement &mdash; more on that in a moment &mdash; but I expressed scepticism that it would yield the same kind of benefits as the Stata case. There are various reasons for my scepticism, including the fact that R's reshaping libraries are already highly optimised for this kind of thing and R generally does a better job of handling missing values.[^1] \n\n[^1]: As good as Stata is at handling rectangular data, it's somewhat notorious for how it handles missing observations. But that's a subject for another day.\n\nSounds like we need a good reshape horserace up in here!\n\n*Insert obligatory joke about time spent reading reshape help files.*\n\n## Benchmarks\n\n### Defaults\n\nSimilar to Ryan, our task will be to reshape wide data (1000 non-index columns) with a lot of missing observations. I'll leave my scripts at the bottom of this post, but first a comparison of the \"default\" reshaping methods. For Stata, that includes the vanilla `reshape` command and the aforementioned `sreshape` command, as well as `greshape` from [**gtools**](https://gtools.readthedocs.io/). For R, we'll use `pivot_longer()` from the tidyverse (i.e. [**tidyr**](https://tidyr.tidyverse.org/)) and `melt()` from [**data.table**](https://rdatatable.gitlab.io/data.table). Note the log scale and the fact that I've rebased everything relative to the fastest option.\n\n![]({{ site.url }}/posts/img/reshape-benchmarks-defaults.png)\n\nUnsuprisingly, `data.table::melt()` is easily the fastest method. However, `tidyr::pivot_longer()` gives a very decent account of itself and is about three times as fast as **gtools**' `greshape`. The base Stata `reshape` option is hopelessly slow for this task, demonstrating (among other things) the difficulty it has with missing values.\n\n### Manual implementation\n\nDefaults out of the way, let's implement the manual split-apply-combine approach in R. Again, I'll leave my scripts at the bottom of the post for you to look at, but I'm essentially just following (variants of) the approach that Ryan adroitly lays out. Note that both `tidyr::pivot_longer()` and `data.table::melt()` provide options to drop missing values, so I'm going to try those out too.\n\n![]({{ site.url }}/posts/img/reshape-benchmarks-all.png)\n\nAs expected, the manual split-apply-combine approach(es) don't yield any benefits in the R case. In fact, quite the opposite, with it resulting in a rather sizeable performance loss. (Yes, I know that I could try running things in parallel but I can already tell you that the extra overhead won't be worth it for this particular example.)\n\n## Bottom line\n\nFor reshaping sparse data, you can't really do much better than sticking with the defaults in R. **data.table** remains a speed marvel, although **tidyr** gives very good account of itself too. Stata users should definitely switch to **gtools** if they aren't using it already.\n\n<i>**Update:**</i> Follow-up post [here]({{ site.baseurl }}{% post_url 2020-07-02-even-more-reshape %}) with additional benchmarks, including other SW languages and a larger dataset.\n\n## Code\n\nAs promised, here is the code. Please let me know if you spot any errors.\n\nFirst, generate the dataset (in R).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries ---------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(data.table)\n\n# Data prep ---------------------------------------------------------------\n\nset.seed(10)\n\nn = 1e6\nn_col=1e3\n\nd = matrix(sample(LETTERS, n, replace=TRUE), ncol=n_col)\n\n## Randomly replace columns with NA values\nfor(i in 1:nrow(d)) {\n    j = sample(2:n_col, 1)\n    d[i, j:n_col] = NA_character_\n  }\nrm(i, j)\n## Ensure at least one row has obs for all columns\nd[1, ] = sample(LETTERS, n_col, replace = TRUE)\n\n## Get non-missing obs group (only really needed for the manual split-apply-combine approaches)\ngrp = apply(d, 1, function(x) sum(!is.na(x)))\n\n## Convert to data frame and name columns\nd = as.data.frame(d)\ncolnames(d) = paste0(\"x\", seq_along(d))\nd$grp = grp\nd$id = row.names(d)\nd = d %>% select(id, grp, everything())\n\n# Export -----------------------------------------------------------------\nfwrite(d, '~/sparse-wide.csv')\n```\n:::\n\n\n\nNext, run the Stata benchmarks.\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nclear\nclear matrix\ntimer clear\nset more off\n\nimport delimited \"~/sparse-wide.csv\"\n\n// Vanilla Stata\npreserve\ntimer on 1\nreshape long x, i(id grp) j(variable) \ntimer off 1\nrestore\n\n// sreshape\n// net install dm0090\npreserve\ntimer on 2\nsreshape long x, i(id grp) j(variable) missing(drop all)\ntimer off 2\nrestore\n\n// gtools\n// ssc install gtools\npreserve\ntimer on 3\ngreshape long x, by(id grp) key(variable)\ntimer off 3\nrestore\n\ntimer list\n\ndrop _all\ngen result = .\nset obs 3\ntimer list\nforval j = 1/3{\n\treplace result = r(t`j') if _n == `j'\n}\noutsheet using \"~/sparse-reshape-stata.csv\", replace\n```\n:::\n\n\n\nFinally, let's run the R benchmarks and compare.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries ---------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(microbenchmark)\nlibrary(hrbrthemes)\ntheme_set(theme_ipsum())\n\n# tidyverse ---------------------------------------------------------------\n\n## Default\ntidy_pivot = function() pivot_longer(d, -c(id, grp))\n## Default with na.rm argument\ntidy_pivot_narm = function() pivot_longer(d, -c(id, grp), values_drop_na = TRUE)\n## Manual split-apply-combine approach\ntidy_split = function() map_dfr(unique(d$grp), function(i) pivot_longer(filter(d, grp==i)[1:(i+2)], -c(id, grp)))\n## Version of manual split-apply-combine approach that uses nesting\ntidy_nest = function() {\n  d %>%\n    group_nest(grp) %>%\n    mutate(data = map2(data, grp, ~ select(.x, 1:(.y+1)))) %>%\n    mutate(data = map(data, ~ pivot_longer(.x, -id))) %>%\n    unnest(cols = data)\n}\n\n# data.table --------------------------------------------------------------\n\nDT = as.data.table(d)\n## Default\ndt_melt = function() melt(DT, id.vars = c('id', 'grp'))\n## Default with na.rm argument\ndt_melt_narm = function() melt(DT, id.vars = c('id', 'grp'), na.rm = TRUE)\n## Manual split-apply-combine approach\ndt_split = function() rbindlist(lapply(unique(DT$grp), function(i) melt(DT[grp==i, 1:(i+2)], id.vars=c('id','grp'))))\n\n# Benchmark ---------------------------------------------------------------\n\nb = microbenchmark(tidy_pivot(), tidy_pivot_narm(), tidy_split(), tidy_nest(), \n                   dt_melt(), dt_melt_narm(), dt_split(), \n                   times = 5)\nb\nautoplot(b)\n\n# Comparison with Stata results -------------------------------------------\n\nstata = fread('~/sparse-reshape-stata.csv')\nstata$method = c('reshape', 'sreshape', 'gtools')\nstata$sw = 'Stata'\n\nr = data.table(result = print(b, 's')$median, ## just take the median time\n               method = gsub('\\\\(\\\\)', '', print(b)$expr),\n               sw = 'R'\n               )\n\nres = rbind(r, stata)\nres[, rel_speed := result/min(result)]\n\ncapn = paste0('Task: Wide to long reshaping of an unbalanced (sparse) ', nrow(d),\n              ' Ã— ', ncol(d), ' data frame with two ID variables.')\n\n## Defaults only\nggplot(res[method %chin% c('dt_melt', 'tidy_pivot', 'gtools', 'sreshape', 'reshape')], \n       aes(x = rel_speed, y = fct_reorder(method, rel_speed), col = sw, fill = sw)) +\n  geom_col() +\n  scale_x_log10() +\n  scale_color_brewer(palette = 'Set1') + scale_fill_brewer(palette = 'Set1') +\n  labs(x = 'Time (relative to fastest method)', y = 'Method', title = 'Reshape benchmark', \n       subtitle = 'Default methods only',\n       caption = capn)\n\n## All\nggplot(res, aes(x = rel_speed, y = fct_reorder(method, rel_speed), col = sw, fill = sw)) +\n  geom_col() +\n  scale_x_log10() +\n  labs(x = 'Time (relative to fastest method)', y = 'Method', title = 'Reshape benchmark', \n       caption = capn) +\n  scale_color_brewer(palette = 'Set1') + scale_fill_brewer(palette = 'Set1') \n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}